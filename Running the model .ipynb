{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9de31c",
   "metadata": {},
   "source": [
    "## Explanation of what to do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name =  \"data_all\"\n",
    "model_name = \"\"\n",
    "\n",
    "## Initialise model \n",
    "model = Model(*read_in_data(data_name),model_name  )\n",
    "## Precurrated model \n",
    "model = Model_Import(model_name + \".pickle\")\n",
    "\n",
    "Run_Model(model,\n",
    "          C_values = np.linspace(1, 10, 10),\n",
    "          Gamma_values= np.linspace(0.0001, 0.001, 10),\n",
    "         balance_data = False, \n",
    "         feature_reduction = False, \n",
    "         search = \"grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_efficiency(self, n, l = 4):\n",
    "    \"\"\"\n",
    "    Plot the variance given by the sum distance of all points to their respective cluster centroids. \n",
    "    Number of cluster centroids are predetermined as scalar multiples of the oversampled class length. \n",
    "    \"\"\"\n",
    "    categorical_index = [i for i in range(l, len(self.feature_index))]\n",
    "    y_train = self.y_train \n",
    "    X_train = self.X_train \n",
    "    train = np.column_stack((X_train,y_train))\n",
    "    train_pos = train[train[:,-1] == 1]\n",
    "    X_train_pos = train[train[:,-1] == 1][:,:-1].copy()\n",
    "    X_train_neg = train[train[:,-1] == 0][:,:-1].copy()\n",
    "\n",
    "\n",
    "    km = KPrototypes(n_clusters = int(X_train_pos.shape[0]*n)).fit(X_train_neg, categorical = categorical_index)\n",
    "    print(km.cost_)\n",
    "    return km.cost_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd76a0bd",
   "metadata": {},
   "source": [
    "## AR data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aefb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pickle \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "from imblearn.over_sampling import SMOTENC \n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def Model_Export(model, name): \n",
    "    pickle_out = open(\"model/\" + name + \".pickle\", \"wb\")\n",
    "    pickle.dump(model, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "def Model_Import(file): \n",
    "    pickle_in = open(\"model/\" + file, \"rb\")\n",
    "    return pickle.load(pickle_in)\n",
    "\n",
    "def read_in_data(name):\n",
    "    Import = open(\"data/clean_data/\" + name + \".pickle\", \"rb\")\n",
    "    X_train, X_test, y_train, y_test, feature_index = pickle.load(Import)\n",
    "    return X_train, X_test, y_train, y_test, feature_index \n",
    "\n",
    "def metrics(true, predict):\n",
    "    ### Need to add the reference to Bobra \n",
    "    TN = 0.\n",
    "    TP = 0.\n",
    "    FP = 0.\n",
    "    FN = 0.\n",
    "    for i in range(len(predict)):\n",
    "        if (predict[i] == 0 and true[i] == 0):\n",
    "            TN += 1\n",
    "        elif (predict[i] == 1 and true[i] == 0):\n",
    "            FP += 1\n",
    "        elif (predict[i] == 1 and true[i] == 1):\n",
    "            TP += 1\n",
    "        elif (predict[i] == 0 and true[i] == 1):\n",
    "            FN += 1\n",
    "\n",
    "    return TN, FP, TP, FN\n",
    "\n",
    "def TSS(true, predict): \n",
    "    TN, FP, TP, FN = metrics(true, predict)\n",
    "    return (TP/(TP+FN)) - ( FP/(FP+TN))\n",
    "\n",
    "\n",
    "\n",
    "class Model: \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self,X_train, X_test, y_train, y_test, feature_index, name):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test, self.feature_index, self.name = X_train, X_test, y_train, y_test, feature_index, name\n",
    "        self.id =  time.strftime(\"%d%m%Y%H%M\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def feature_reduction(self,method = \"F_score\", threshold = False):\n",
    "        \"\"\"\n",
    "        Reduce the amount of features in the dataset. Three methods can be used: F-score, L1-svm, and Logistic regression. If \n",
    "        using F-scoring, an adittional parameter of threshold must be added, where threshold is the what is the minumum F-score\n",
    "        for features selected \n",
    "        \"\"\"\n",
    "        X_train = self.X_train\n",
    "        y_train = self.y_train\n",
    "        X_test = self.X_test\n",
    "        if method == \"F_score\":\n",
    "            scorer = SelectKBest(k = \"all\").fit(X_train, y_train)\n",
    "            F_score_data = pd.DataFrame( scorer.scores_)\n",
    "            F_score_data.index = feature_index\n",
    "            F_score_data.columns = [\"F-score\"]\n",
    "            self.F_score_data = F_score_data\n",
    "            if threshold == False: \n",
    "                return \"Look up F-score data to decide a threshold \"\n",
    "            else: \n",
    "                new_feature_index = F_score_data[F_score_data[\"F-score\"] > threshold].index\n",
    "                best_no = F_score_data[F_score_data[\"F-score\"] > threshold].shape[0]\n",
    "                print(X_train.shape)\n",
    "                X_train_new = SelectKBest(k = best_no).fit_transform(X_train, y_train)\n",
    "                print(X_train_new.shape)\n",
    "                self.X_train = X_train_new \n",
    "                X_test = pd.DataFrame(X_test)\n",
    "                X_test.columns = self.feature_index\n",
    "                self.X_test = np.array(X_test[new_feature_index])\n",
    "                self.feature_index = new_feature_index \n",
    "                print(\"new feature index:\")\n",
    "                print(new_feature_index)\n",
    "        \n",
    "        if method == \"L1_svm\": \n",
    "            C_values = [2**i for i in range(-5,17,2)]\n",
    "            parameters = {'penalty': ['l1'], \n",
    "                              'C': C_values, \n",
    "                              \"dual\":[False],\n",
    "                         \"class_weight\": [\"balanced\"] }\n",
    "            svc = LinearSVC()\n",
    "            clf = GridSearchCV(svc, parameters,scoring = 'roc_auc' , cv = 5)\n",
    "            clf.fit(X_train, y_train )\n",
    "            model = SelectFromModel(clf.best_estimator_, prefit=True)\n",
    "            print(X_train.shape)\n",
    "            X_train_new = model.transform(X_train)\n",
    "            print(X_train_new.shape)\n",
    "            self.X_train = X_train_new \n",
    "            self.X_test = model.transform(X_test)\n",
    "            self.feature_index = self.feature_index[model.get_support() == True]\n",
    "            print(\"new feature index:\")\n",
    "            print(self.feature_index)\n",
    "            \n",
    "        if method == \"Logistic\": \n",
    "            print(X_train.shape)\n",
    "            selector = SelectFromModel(estimator=LogisticRegression()).fit(X_train, y_train)\n",
    "            X_train_new = selector.transform(X_train)\n",
    "            print(X_train_new.shape)\n",
    "            self.X_train = X_train_new \n",
    "            self.X_test = selector.transform(X_test)\n",
    "            self.feature_index = self.feature_index[selector.get_support() == True]\n",
    "            print(\"new feature index:\")\n",
    "            print(self.feature_index)\n",
    "            \n",
    "        \n",
    "\n",
    "    def balance_data(self, N_clusters, l = 4):\n",
    "        \"\"\"\n",
    "        Balance data by undersampling the negative class via K-prototype clustering and oversampling the positive class\n",
    "        via SMOTE. N_clusters determines amount of datapoints for the undersampling, and categorical index is a list for \n",
    "        all categorical features in the dataset \n",
    "        \n",
    "        \"\"\"\n",
    "        categorical_index = [i for i in range(l, len(self.feature_index))]\n",
    "        \n",
    "        # Seperate positive and negative classes \n",
    "        X_train = self.X_train \n",
    "        train = np.column_stack((X_train_new,y_train))\n",
    "        train_pos = train[train[:,-1] == 1]\n",
    "        X_train_pos = train[train[:,-1] == 1][:,:-1].copy()\n",
    "        X_train_neg = train[train[:,-1] == 0][:,:-1].copy()\n",
    "        \n",
    "        ## undersample the negative class \n",
    "        km = KPrototypes(n_clusters = N_clusters).fit(X_train_neg, categorical = categorical_index)\n",
    "        K_train_neg = km.cluster_centers_\n",
    "        \n",
    "        # Merge positve and negative classes \n",
    "        train_neg = np.column_stack((K_train_neg, np.zeros(K_train_neg.shape[0])))\n",
    "        train_new = np.vstack((train_pos, train_neg))\n",
    "        np.random.shuffle(train_new)\n",
    "        print(\"training data shape\")\n",
    "        print(X_train.shape)\n",
    "        X_new = train_new[:,:-1]\n",
    "        y_new = train_new[:,-1]\n",
    "        ## oversample the positive class \n",
    "        sm =  SMOTENC(categorical_features = categorical_index, random_state=42)\n",
    "        X_res, y_res = sm.fit_resample(X_new, y_new)\n",
    "        print()\n",
    "        print(\"new training data shape\")\n",
    "        print(X_res.shape)\n",
    "        self.X_train = X_res \n",
    "        self.y_train = y_res \n",
    "            \n",
    "            \n",
    "            \n",
    "    def gridsearch(self):\n",
    "        C_values = [10**i for i in range(-2,5)]\n",
    "        Gamma_values = [10**i for i in range(-4,3)]\n",
    "        parameters = {'kernel': ['rbf'], \n",
    "                  'C': C_values, \n",
    "                  \"gamma\":Gamma_values ,\n",
    "                  \"class_weight\": [\"balanced\"] }\n",
    "\n",
    "        svc = SVC()\n",
    "        clf = GridSearchCV(svc, parameters,scoring = 'roc_auc' , cv = 10)\n",
    "        clf.fit(self.X_train, self.y_train )\n",
    "        ranked_data = pd.DataFrame(clf.cv_results_).sort_values(by=['rank_test_score'])\n",
    "        self.grid_data = ranked_data\n",
    "        return ranked_data \n",
    "\n",
    "    \n",
    "    \n",
    "    def finesearch(self,C_values, Gamma_values):\n",
    "        parameters = {'kernel': ['rbf'], \n",
    "                  'C': C_values, \n",
    "                  \"gamma\":Gamma_values ,\n",
    "                  \"class_weight\": [\"balanced\"] }\n",
    "\n",
    "        svc = SVC()\n",
    "        clf = GridSearchCV(svc, parameters,scoring = 'roc_auc' , cv = 10)\n",
    "        clf.fit(self.X_train, self.y_train )\n",
    "        ranked_data = pd.DataFrame(clf.cv_results_).sort_values(by=['rank_test_score'])\n",
    "        self.fine_data = ranked_data\n",
    "        clf_best = clf.best_estimator_\n",
    "        clf_best.fit(self.X_train, self.y_train )\n",
    "        self.final = clf_best\n",
    "        return ranked_data\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0.0001, 0.001, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de84d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in data into the model \n",
    "name =  \"AR_non_occurences\"\n",
    "X,y, feature_index = read_in_data(name)\n",
    "model = Model(X,y, feature_index, \"AR\")\n",
    "\n",
    "# Perform grid search \n",
    "print(\"start model gridsearch\")\n",
    "model.gridsearch()\n",
    "Model_Export(model, model.name)\n",
    "data = model.grid_data\n",
    "data.to_csv(str(model.id) + \"_\" + model.name +\".csv\", index_label=False)\n",
    "print(\"done model gridsearch\")\n",
    "\n",
    "\n",
    "\n",
    "# Perform fine search\n",
    "#C_values = \n",
    "#Gamma_values=\n",
    "#class_weights = \n",
    "#model = Model_Import(\"AR_F_score.pickle\")\n",
    "#print(\"start model finsearch\")\n",
    "#model.finesearch(C_values, Gamma_values, class_weights)\n",
    "#Model_Export(model, model.name)\n",
    "#model.fine_data.to_csv(str(model.id) + \"_fine_\" + model.name +\".csv\", index_label=False)\n",
    "#print(\"end model finsearch\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1631c35",
   "metadata": {},
   "source": [
    "## AR data, l1-svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34692d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "name =  \"AR_non_occurences\"\n",
    "X,y, feature_index = read_in_data(name)\n",
    "model = Model(X,y, feature_index, \"AR_l1svm\")\n",
    "model.feature_reduction(method = \"L1_svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1, 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202f687",
   "metadata": {},
   "source": [
    "## AR data, F-score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac54c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in data into the model \n",
    "name =  \"AR_non_occurences\"\n",
    "X,y, feature_index = read_in_data(name)\n",
    "model = Model(X,y, feature_index, \"AR_Fscore\")\n",
    "# Perform F_score feature selection \n",
    "model.feature_reduction(threshold = 1)\n",
    "\n",
    "# Perform grid search \n",
    "\n",
    "\n",
    "\n",
    "# Perform fine search\n",
    "\n",
    "#model = Model_Import(\"AR_F_score.pickle\")\n",
    "#C_values = np.linspace(2048, 8192, 20)\n",
    "#Gamma_values= [0.000031]\n",
    "#class_weights = [\"balanced\"]\n",
    "#print(\"start model finsearch\")\n",
    "#model.finesearch(C_values, Gamma_values, class_weights)\n",
    "#Model_Export(model, model.name)\n",
    "#model.fine_data.to_csv(str(model.id) + \"_fine_\" + model.name +\".csv\", index_label=False)\n",
    "#print(\"end model finsearch\")\n",
    "\n",
    "\n",
    "\n",
    "# Test \n",
    "#model = Model_Import(\"AR.pickle\") \n",
    "best_C = 512\n",
    "best_gamma = 0.000406901\n",
    "best_cw = \"balanced\"\n",
    "model.test(best_C, best_gamma, best_cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb3602",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "model.test(best_C, best_gamma, best_cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303603b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.performance_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc9f2b",
   "metadata": {},
   "source": [
    "## SHARP data, F-score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853918ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and split \n",
    "name =  \"SHARP_NO\"\n",
    "X,y, feature_index = read_in_data(name)\n",
    "model = Model(X,y, feature_index, \"SHARP\")\n",
    "\n",
    "model.feature_reduction(threshold = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba603ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = 8192\n",
    "best_gamma =  0.00012207\n",
    "best_cw = \"balanced\"\n",
    "model.test(best_C, best_gamma, best_cw)\n",
    "model.performance_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c5287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and split \n",
    "name =  \"SHARP_NO\"\n",
    "X,y, feature_index = read_in_data(name)\n",
    "model = Model(X,y, feature_index, \"SHARP\")\n",
    "\n",
    "model.feature_reduction(threshold = 90)\n",
    "\n",
    "\n",
    "print(\"start model gridsearch\")\n",
    "model.gridsearch()\n",
    "Model_Export(model, model.name)\n",
    "data = model.grid_data\n",
    "data.to_csv(str(model.id) + \"_\" + model.name +\".csv\", index_label=False)\n",
    "print(\"done model gridsearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ab99b",
   "metadata": {},
   "source": [
    "## SHARP data 48 hrs, F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0359edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and split \n",
    "name =  \"SHARP_48\"\n",
    "X,y, feature_index = read_in_data(name)\n",
    "model = Model(X,y, feature_index, name)\n",
    "\n",
    "model.feature_reduction(threshold = 90)\n",
    "\n",
    "\n",
    "#print(\"start model gridsearch\")\n",
    "#model.gridsearch()\n",
    "#Model_Export(model, model.name)\n",
    "#data = model.grid_data\n",
    "#data.to_csv(str(model.id) + \"_\" + model.name +\".csv\", index_label=False)\n",
    "#print(\"done model gridsearch\")\n",
    "\n",
    "best_C = 32768\n",
    "best_gamma =  0.0001220703125\n",
    "best_cw = \"balanced\"\n",
    "model.test(best_C, best_gamma, best_cw)\n",
    "model.performance_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f9efe",
   "metadata": {},
   "source": [
    "## Try new things "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr= LogisticRegression(solver='lbfgs',random_state=42,max_iter=10000)\n",
    "name =  \"SHARP_48\"\n",
    "X,y, feature_index = read_in_data(name)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "ligma = lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.F_score_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name =  \"AR_non_occurences\"\n",
    "X,y, feature_index = read_in_data(name)\n",
    "model = Model(X,y, feature_index, \"AR\")\n",
    "\n",
    "model.feature_reduction(method = \"Logistic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ebf592",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(ligma, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb888c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f912f9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
